<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>GENEA Workshop 2023
  </title>

  <!-- Bootstrap core CSS -->
  <link href="/2023/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="/2023/vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="/2023/css/iva.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">GENEA Challenge 2023</span>
      <!-- <span class="d-none d-lg-block">
        <img src="img/avatar.png" class="img-fluid img-profile rounded-circle mx-auto mb-5" alt="">

      </span> -->
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#home">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#important-dates">Important dates</a>
        </li>
        
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#workshop-programme">Workshop programme</a>
        </li>

        <!--
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-papers">Call for papers</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#reproducibility-award">Reproducibility Award</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#invited-speakers">Invited speakers</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#accepted-papers">Accepted papers</a>
        </li>
        -->
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#organising-committee">Organising committee</a>
        </li>
        <!--
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#program-committee">Program committee</a>
        </li>
      -->
      </ul>
    </div>
  </nav>


  <div class="container-fluid p-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="home">
      <div class="w-100">
        <div class="row">
          <div class="col-md-9 col-sm-12">
            <div> <img src="/2023/img/GENEA_logo.png"  class="img-fluid rounded" class="mt-2" width=300 alt="GENEA" title="GENEA"> </div>
            <div>
                <h2 class="mb-2">
                 Workshop 2023
                </h2>
            </div>

            <div class="subheading mb-5">Generation and Evaluation of Non-verbal Behaviour for Embodied Agents</div>
            <!--  -->

            <p class="mb-5">
              <b>Official ICMI 2023 Workshop – October 9-13 (to be determined) </b><br><br>
              

              The GENEA (Generation and Evaluation of Non-verbal Behaviour for Embodied Agents) Workshop
              2023 aims at bringing together researchers that use different methods for non-verbal-behaviour generation
              and evaluation, and hopes to stimulate the discussions on how to improve both the
              generation methods and the evaluation of the results. We invite all interested researchers to submit a paper related to their
              work in the area and to participate in the workshop. This is the fourth installment of the GENEA Workshop,
              for more information about the 2022 installment, please go <a href="https://genea-workshop.github.io/2022/" target="_blank">here</a>.<br><br>


            </p>
            <div class="row justify-content-center">

              <img src="/2023/img/avatar.png"  class="img-fluid rounded" class="mt-2" width=300 alt="">
            </div>
          </div>
          <div class="col-md-3 d-none d-md-block">
            <a class="twitter-timeline" data-tweet-limit=3 href="https://twitter.com/WorkshopGenea?ref_src=twsrc%5Etfw" target="_blank">Follow us on twitter <i class="fab fa-twitter"></i></a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </div>
          <div class="col-xs-12 d-md-none mt-4 text-center w-100">
            <a href="https://twitter.com/WorkshopGenea" target="_blank">Follow us on Twitter <i class="fab fa-twitter"></i></a>
          </div>
        </div>
      </div>

    </section>

    <hr class="m-0">

    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="important-dates">
      <div class="w-100">
        <h2 class="mb-5">Important dates</h2>
       <div class="row">
          <div class="col">July 23, 2023</div>
          <div class="col">Submission deadline</div>
        </div>
        <div class="row">
          <div class="col">August 4, 2023</div>
          <div class="col">Notifications</div>
        </div>
        <div class="row">
          <div class="col">August 11, 2023</div>
          <div class="col">Camera-ready deadline</div>
        </div>
        <div class="row">
          <div class="col">October 9-13, 2023</div>
          <div class="col">Workshop (Physical)</div>
        </div>

    </section>

    <hr class="m-0">

    <!--
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="workshop-programme">
      <div class="w-100">
        <h2 class="mb-5">Planned Workshop programme</h2>
        <h4>All times in India Standard Time</h4>
        <div>Note, all times are in the <a href="https://everytimezone.com/s/0f610aec" target="_blank">India Standard timezone</a>. The workshop will take place virtually over Zoom on November 7th. <br><br></div>
        <div class="row">
            <div class="col"> <a href="https://everytimezone.com/s/0f610aec" target="_blank">14:30&nbsp;-&nbsp;14:45</a> </div>
            <div class="col-10">Opening statement</div>
        </div>
        <div class="row">
            <div class="col"> <a href="https://everytimezone.com/s/8e829508" target="_blank">14:45&nbsp;-&nbsp;15:30</a> </div>
            <div class="col-10">Keynote presentation by Carlos T.Ishi</div>
        </div>
        <div class="row">
          <div class="col"> <a href="https://everytimezone.com/s/0d30da32" target="_blank">15:30&nbsp;-&nbsp;15:40</a> </div>
          <div class="col-10">Break (Optional socialisation on gather.town)</div>
        </div>
        <div class="row">
            <div class="col"> 15:40&nbsp;-&nbsp;17:00</div>
            <div class="col-10">Workshop paper presentations</div>
        </div>
        <div class="row">
          <ul style="list-style: none">
            <li><span style="margin-right: 10px;"> </span> <a href="https://openreview.net/pdf?id=T5ei7IeQUMK" target="_blank">Understanding Interviewees’ Perceptionsß and Behaviour towards Verbally and Non-verbally Expressive Virtual Interviewing Agents</a> by Jinal Thakkar, Pooja S. B. Rao, Kumar Shubham, Vaibhav Jain, Dinesh Babu Jayagopi</li>
            <li><span style="margin-right: 10px;"> </span> <a href="https://openreview.net/pdf?id=vaOobiePUy" target="_blank">Emotional Respiration Speech Dataset</a> by Rozemarijn Roes, Francisca Pessanha, Almila Akdag</li>
            <li><span style="margin-right: 10px;"> </span> <a href="https://openreview.net/pdf?id=TmR8Q20jL-" target="_blank">Automatic facial expressions, gaze direction and head movements generation of a virtual agent</a> by Alice Delbosc, Stéphane Ayache, Magalie Ochs</li>
            <li><span style="margin-right: 10px;"> </span> <a href="https://openreview.net/pdf?id=by_w1j6XAwr" target="_blank">Can you tell that I'm confused? An overhearer study for German backchannels by an embodied agent</a> by Isabel Donya Meywirth, Jana Götze</li>
          </ul>
        </div>
        <div class="row">
          <div class="col">17:00&nbsp;-&nbsp;17:15</div>
          <div class="col-10">Break (Optional socialisation on gather.town)</div>
        </div>
        <div class="row">
          <div class="col"> <a href="https://everytimezone.com/s/be641ea2" target="_blank">17:15&nbsp;-&nbsp;18:00</a> </div>
          <div class="col-10">Keynote presentation by Judith Holler</div>
        </div>
        <div class="row">
          <div class="col">18:00&nbsp;-&nbsp;18:25</div>
          <div class="col-10">Group discussion</div>
        </div>
        <div class="row">
          <div class="col"> <a href="https://everytimezone.com/s/3001ce50" target="_blank">18:25&nbsp;-&nbsp;18:30</a> </div>
          <div class="col-10">Reproducibility award and Closing remarks</div>
        </div>
        <div class="row">
          <div class="col">18:30&nbsp;-&nbsp;</div>
          <div class="col-10">Informal mingle</div>
        </div>
      </div>
    </section>
    -->
    <!--
    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="call-for-papers">
      
      <div class="w-100">
        <h2 class="mb-5">Call for papers</h2>

        <div class="iva-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="iva-content">
            <p> GENEA 2023 is the third GENEA workshop and an official workshop of ACM ICMI’23, and will be hybrid: will take place both in Paris, France, and online. Accepted workshop submissions will be included in the adjunct ACM ICMI proceedings.</p>

            <p>Generating non-verbal behaviours, such as gesticulation, facial expressions and gaze, is of great importance for natural interaction with embodied agents such as virtual agents and social robots. At present, behaviour generation is typically powered by rule-based systems, data-driven approaches, and their hybrids. For evaluation, both objective and subjective methods exist, but their application and validity are frequently a point of contention.</p>

            <p>This workshop asks, “What will be the behaviour-generation methods of the future? And how can we evaluate these methods using meaningful objective and subjective metrics?” The aim of the workshop is to bring together researchers working on the generation and evaluation of non-verbal behaviours for embodied agents to discuss the future of this field. To kickstart these discussions, we invite all interested researchers to submit a paper for presentation at the workshop.<p>

            <h4>Paper topics include (but are not limited to) the following</h4>
            <ul>
              <li>Automated synthesis of facial expressions, gestures, and gaze movements</li>
              <li>Audio- and music-driven nonverbal behaviour synthesis</li>
              <li>Closed-loop nonverbal behaviour generation (from perception to action)</li>
              <li>Nonverbal behaviour synthesis in two-party and group interactions</li>
              <li>Emotion-driven and stylistic nonverbal behaviour synthesis</li>
              <li>New datasets related to nonverbal behaviour</li>
              <li>Believable nonverbal behaviour synthesis using motion-capture and 4D scan data</li>
              <li>Multi-modal nonverbal behaviour synthesis</li>
              <li>Interactive/autonomous nonverbal behavior generation</li>
              <li>Subjective and objective evaluation methods for nonverbal behaviour synthesis</li>
              <li>Guidelines for nonverbal behaviours in human-agent interaction</li>
            </ul>

            <p>To encourage authors to make their work reproducible and reward the effort that this requires, we have introduced the <a class="js-scroll-trigger" href="#reproducibility-award">GENEA Reproducibility Award</a>.
          </div>
        </div>
      </div>
    </section>

    <hr class="m-0">    
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="reproducibility-award">

      <div class="w-100">
        <h2 class="mb-5">Reproducibility Award</h2>
        Reproducibility is a cornerstone of the scientific method. Lack of reproducibility is a serious issue in contemporary research which we want to address at our workshop. To encourage authors to make their papers reproducible, and to reward the effort that reproducibility requires, we are introducing the GENEA Workshop Reproducibility Award. All short and long papers presented at the GENEA Workshop will be eligible for this award. Please note that it is the camera-ready version of the paper which will be evaluated for the reward.
        <br><br>
        The award is awarded to the paper with the greatest degree of reproducibility. The assessment criteria include:
        <ul>
          <li>ease of reproduction (ideal: just works, if there is code - it is well documented and we can run it)</li>
          <li>extent (ideal: all results can be verified)</li>
          <li>data accessibility (ideal: all data used is publicly available)</li>
        </ul>
      </div>

    </section>
    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="invited-speakers">
      <div class="w-100">
        <h2 class="mb-5">Invited speakers</h2>
        
        <h3 class="mt-5" id="carlos_ishi"><a href="https://dil.atr.jp/~carlos/">Carlos T. Ishi (RIKEN and ATR)</a></h3>
                <div class="row">
                  <div class="col-2"><a href="https://dil.atr.jp/~carlos/"> <img src="/2023/img/carlos.jpg"
                      style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Carlos T. Ishi"></a></div>
                  <div class="col-10"><h5>Biography</h5>
                      Carlos T. Ishi received the PhD degree in engineering from The University of Tokyo, Japan. He joined ATR Intelligent Robotics and Communication Labs in 2005, and became the group leader of the Dept. of Sound Environment Intelligence since 2013. He joined the Guardian Robot Project, RIKEN, in 2020. His research topics include analysis and processing of dialogue speech and non-verbal behaviors applied for human-robot interaction.
                    <br>
                    <br>
                    <h5>Talk - Analysis and generation of speech-related motions, and evaluation in humanoid robots</h5>
                    The generation of motions coordinated with speech utterances is important for dialogue robots or avatars, in both autonomous and tele-operated systems, to express humanlikeness and tele-presence. For that purpose, we have been studying on the relationships between speech and motion, and methods to generate motions from speech, for example, lip motion from formants, head motion from dialogue functions, facial and upper body motions coordinated with vocalized emotional expressions (such as laughter and surprise), hand gestures from linguistic and prosodic information, and gaze behaviors from dialogue states. In this talk, I will give an overview of our research activities on motion analysis and generation, and evaluation of speech-driven motions generated in several humanoid robots (such as the android ERICA, and a desktop robot CommU).
                  </div>
                </div>


        <h3 class="mt-5" id="judith_holler"><a href="https://www.mpi.nl/people/holler-judith"> Judith Holler (Radboud University)</a></h3>
        <div class="row">
          <div class="col-2"><a href="https://www.mpi.nl/people/holler-judith"><img src="/2023/img/judith.jpg"
            style=" margin-right: 30px; margin-bottom: 10px" class="img-fluid rounded" alt="Judith Holler"></a></div>
          <div class="col-10"><h5>Biography</h5>
          Judith is Associate prof and PI at the Donders Institute for Brain, Cognition, & Behaviour (Radboud University) and leader of the research group Communication in Social Interaction at the Max Planck Institute for Psycholinguistics. Judith has been a Marie Curie Fellow and currently holds an ERC Consolidator grant. The focus of her work is on the interplay of speech and visual bodily signals from the hands, head, face, and eye gaze, in communicating meaning in interaction. In her scientific approach, she combines analyses of natural language corpora with experimental testing, and methods from a wide range of fields, including gesture studies, linguistics, psycholinguistics, and neuroscience. In her most recent projects, she combines these methods also with cutting-edge tools and techniques, such as virtual reality, mobile eyetracking, and dual-EEG to further our insights into multimodal communication and coordination in social interaction. 
            <br>
            <br>
            <h5>Talk - Towards generating artificial agents with multimodal pragmatic behaviour</h5>
            Traditionally, visual bodily movements have been associated with the communication of affect and emotion. In this talk, I will throw light on the pragmatic contribution that visual bodily movements make in conversation. In doing so, I will focus on fundamental processes that are key in achieving mutual understanding in talk: producing recipient-designed messages, signalling understanding, trouble in understanding and repairing problems in understanding, and the communication of social actions (or “speech” acts). The findings I present highlight the need for equipping artificial agents with multimodal pragmatic capacities, and some ways which may be a fruitful starting point for doing so.
          </div>
        </div>
      </div>
    </section>

    
  
    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="accepted-papers">
      <div class="w-100">
        <h2 class="mb-5">Accepted papers</h2>
        
                <p>
                  <h4><a href="https://openreview.net/forum?id=T5ei7IeQUMK" target="_blank">Understanding Interviewees’ Perceptions and Behaviour towards Verbally and Non-verbally Expressive Virtual Interviewing Agents</a></h4>
                  <i>Jinal Thakkar, Pooja S. B. Rao, Kumar Shubham, Vaibhav Jain, Dinesh Babu Jayagopi</i><br><br>
                </p>
                  <hr>
                <p>
                  <h4><a href="https://openreview.net/forum?id=vaOobiePUy" target="_blank">Emotional Respiration Speech Dataset</a></h4>
                  <i>Rozemarijn Roes, Francisca Pessanha, Almila Akdag</i><br><br>
                </p>
                <hr>
                <p><h4><a href="https://openreview.net/forum?id=TmR8Q20jL-" target="_blank">Automatic facial expressions, gaze direction and head movements generation of a virtual agent</a></h4>
                  <i>Alice Delbosc, Stéphane Ayache, Magalie Ochs</i><br><br>
                </p>

                <hr>
                <p><h4><a href="https://openreview.net/forum?id=by_w1j6XAwr" target="_blank">Can you tell that I'm confused? An overhearer study for German backchannels by an embodied agent</a></h4>
                  <i>Isabel Donya Meywirth, Jana Götze</i><br><br>
                </p>
    </div>
    </section>
    

    
  -->


    <hr class="m-0">
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="organising-committee">
      <div class="w-100">
        <h2 class="mb-5">Organising committee</h2>
        <p>
          The main contact address of the workshop is: <a
            href="mailto:genea-contact@googlegroups.com">genea-contact@googlegroups.com</a>. <br> <br>
          </p>
        <h4>Workshop organisers</h4>

        <div class="row">


          <div class="col-sm-12 col-md-6">
                  <div class="row">
                      <div class="col-5">
                          <img src="/2023/img/youngwoo.jpg" class="img-fluid rounded" alt="Youngwoo Yoon">
                      </div>
                      <div class="col-7">

                          <a href="https://sites.google.com/view/youngwoo-yoon/" target="_blank" style="font-weight: bold;">Youngwoo Yoon</a>
                          <br>ETRI <br> South Korea


                      </div>
                  </div>
                  <hr>
          </div>
          <div class="col-sm-12 col-md-6">
            <div class="row">
                <div class="col-5">
                    <img src="/2023/img/taras.jpg" class="img-fluid rounded" alt="Taras Kucherenko">
                </div>
                <div class="col-7">
                    <a href="https://svito-zar.github.io/" target="_blank" style="font-weight: bold;">Taras Kucherenko</a>
                    <br>
                    Electronic Arts (EA) <br> Sweden

                </div>
            </div>
            <hr>
              
              </div>
          </div>
   

      <div class="row">

          <div class="col-sm-12 col-md-6">
              <div class="row">
                  <div class="col-5">
                      <img src="/2023/img/rajmund.png" class="img-fluid rounded" alt="Rajmund Nagy">
                  </div>
                  <div class="col-7">

                      <a href="https://nagyrajmund.github.io/" target="_blank" style="font-weight: bold;">Rajmund Nagy</a>
                      <br>
                      KTH Royal Institute of Technology <br> Sweden


                  </div>
              </div>
              <hr>
          </div>

          <div class="col-sm-12 col-md-6">
            <div class="row">
              <div class="col-5">
                <img src="/2022/img/pieter.jpeg" width="100%" class="img-fluid rounded" alt="Pieter Wolfert">
              </div>
              <div class="col-7">
                  <a href="https://www.pieterwolfert.com" target="_blank" style="font-weight: bold;">Pieter Wolfert</a>
                  <br>
                  IDLab, Ghent University - imec <br> Belgium
              </div>
            </div>
            <hr>
          </div>



      </div>

      <div class="row">

        <div class="col-sm-12 col-md-6">
          <div class="row">
            <div class="col-5">
              <img src="/2022/img/gustav.jpeg" class="img-fluid rounded" alt="Gustav Eje Henter">
            </div>
            <div class="col-7">

              <a href="https://people.kth.se/~ghe/" target="_blank" style="font-weight: bold;">Gustav Eje Henter</a>
              <br>
              KTH Royal Institute of Technology <br> Sweden


            </div>
          </div>
          <hr>
        </div>

        <div class="col-sm-12 col-md-6">
            <div class="row">
                <div class="col-5">
                    <img src="/2023/img/jieyeon.png" class="img-fluid rounded" alt="Jieyeon Woo">
                </div>
                <div class="col-7">

                    <a href="https://www.jieywoo.com/" target="_blank" style="font-weight: bold;">Jieyeon Woo</a>
                    <br>
                    Sorbonne University <br> France


                </div>
            </div>
            <hr>
        </div>



    </div>

      </div>
    </section>
    <!--
    <hr class="m-0">

    
    <section class="iva-section p-3 p-lg-5 d-flex align-items-center" id="program-committee">
      <div class="w-100">
        <h2 class="mb-5">Program committee</h2>
        <ul>
                  <li>None yet.</li>
                </ul>
      </div>

    </section>
    <hr class="m-0">
  -->


  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="/2023/vendor/jquery/jquery.min.js"></script>
  <script src="/2023/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="/2023/vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="/2023/js/iva.min.js"></script>

</body>

<!-- Panelbear -->
<script async src="https://cdn.panelbear.com/analytics.js?site=9bGH0f0hxBy"></script>
<script>
    window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    panelbear('config', { site: '9bGH0f0hxBy' });
</script>

</html>
